{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 15:53:39.194393: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "vgg=VGG16(weights=\"imagenet\",include_top=False,input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=Flatten()(vgg.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(vgg)\n",
    "# model.add\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale = 1./255,\n",
    "                                 shear_range =0.2,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# val_datagen=ImageDataGenerator(rescale = 1./255,\n",
    "#                                  shear_range =0.2,\n",
    "#                                  zoom_range = 0.2,\n",
    "#                                  horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13492 images belonging to 100 classes.\n",
      "Found 500 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory(r\"/home/tihan/Desktop/hemanth/archive/train/\",target_size=(224,224),batch_size=10,shuffle=True,class_mode=\"categorical\")\n",
    "test_set=test_datagen.flow_from_directory(r\"/home/tihan/Desktop/hemanth/archive/test/\",target_size=(224,224),batch_size=10,class_mode=\"categorical\")\n",
    "# valid_set = val_datagen.flow_from_directory(\n",
    "#     directory=r\"/home/tihan/Desktop/hemanth/archive/valid/\",\n",
    "#     target_size=(224, 224),\n",
    "#     batch_size=10,\n",
    "#     class_mode=\"categorical\",\n",
    "#     shuffle=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21375/2596593733.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r=model.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 437s 970ms/step - loss: 4.2676 - accuracy: 0.0591 - val_loss: 3.6382 - val_accuracy: 0.0875\n",
      "Epoch 2/200\n",
      "450/450 [==============================] - 447s 994ms/step - loss: 3.2785 - accuracy: 0.1822 - val_loss: 2.6735 - val_accuracy: 0.2625\n",
      "Epoch 3/200\n",
      "450/450 [==============================] - 445s 989ms/step - loss: 2.7061 - accuracy: 0.2832 - val_loss: 2.2210 - val_accuracy: 0.3063\n",
      "Epoch 4/200\n",
      "450/450 [==============================] - 446s 991ms/step - loss: 2.4545 - accuracy: 0.3253 - val_loss: 2.1669 - val_accuracy: 0.4250\n",
      "Epoch 5/200\n",
      "450/450 [==============================] - 445s 990ms/step - loss: 2.2925 - accuracy: 0.3740 - val_loss: 1.9237 - val_accuracy: 0.4938\n",
      "Epoch 6/200\n",
      "450/450 [==============================] - 445s 989ms/step - loss: 2.1676 - accuracy: 0.3927 - val_loss: 1.8678 - val_accuracy: 0.4688\n",
      "Epoch 7/200\n",
      "450/450 [==============================] - 445s 988ms/step - loss: 2.0998 - accuracy: 0.4067 - val_loss: 1.8781 - val_accuracy: 0.4437\n",
      "Epoch 8/200\n",
      "450/450 [==============================] - 446s 990ms/step - loss: 1.9946 - accuracy: 0.4402 - val_loss: 1.9555 - val_accuracy: 0.4750\n",
      "Epoch 9/200\n",
      "450/450 [==============================] - 447s 993ms/step - loss: 1.8953 - accuracy: 0.4378 - val_loss: 1.8748 - val_accuracy: 0.4563\n",
      "Epoch 10/200\n",
      "450/450 [==============================] - 446s 990ms/step - loss: 1.8659 - accuracy: 0.4607 - val_loss: 1.7351 - val_accuracy: 0.4812\n",
      "Epoch 11/200\n",
      "450/450 [==============================] - 443s 984ms/step - loss: 1.8378 - accuracy: 0.4735 - val_loss: 1.7104 - val_accuracy: 0.4938\n",
      "Epoch 12/200\n",
      "450/450 [==============================] - 443s 984ms/step - loss: 1.7520 - accuracy: 0.4918 - val_loss: 1.6310 - val_accuracy: 0.5312\n",
      "Epoch 13/200\n",
      "450/450 [==============================] - 447s 993ms/step - loss: 1.7618 - accuracy: 0.4929 - val_loss: 1.6747 - val_accuracy: 0.4688\n",
      "Epoch 14/200\n",
      "450/450 [==============================] - 452s 1s/step - loss: 1.6795 - accuracy: 0.5087 - val_loss: 1.7295 - val_accuracy: 0.4688\n",
      "Epoch 15/200\n",
      "450/450 [==============================] - 444s 987ms/step - loss: 1.6510 - accuracy: 0.5118 - val_loss: 1.6426 - val_accuracy: 0.4938\n",
      "Epoch 16/200\n",
      "450/450 [==============================] - 445s 990ms/step - loss: 1.6200 - accuracy: 0.5200 - val_loss: 1.6795 - val_accuracy: 0.4812\n",
      "Epoch 17/200\n",
      "450/450 [==============================] - 444s 988ms/step - loss: 1.6064 - accuracy: 0.5169 - val_loss: 1.7931 - val_accuracy: 0.5125\n",
      "Epoch 18/200\n",
      "450/450 [==============================] - 444s 986ms/step - loss: 1.5628 - accuracy: 0.5452 - val_loss: 1.5617 - val_accuracy: 0.4938\n",
      "Epoch 19/200\n",
      "450/450 [==============================] - 456s 1s/step - loss: 1.5495 - accuracy: 0.5387 - val_loss: 1.8110 - val_accuracy: 0.4688\n",
      "Epoch 20/200\n",
      "450/450 [==============================] - 445s 989ms/step - loss: 1.5755 - accuracy: 0.5376 - val_loss: 1.8329 - val_accuracy: 0.4688\n",
      "Epoch 21/200\n",
      "450/450 [==============================] - 443s 985ms/step - loss: 1.5092 - accuracy: 0.5528 - val_loss: 1.6329 - val_accuracy: 0.5375\n",
      "Epoch 22/200\n",
      "450/450 [==============================] - 442s 983ms/step - loss: 1.4891 - accuracy: 0.5569 - val_loss: 1.5821 - val_accuracy: 0.5750\n",
      "Epoch 23/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 1.4685 - accuracy: 0.5536 - val_loss: 1.6719 - val_accuracy: 0.5250\n",
      "Epoch 24/200\n",
      "450/450 [==============================] - 442s 983ms/step - loss: 1.4457 - accuracy: 0.5764 - val_loss: 1.6311 - val_accuracy: 0.5250\n",
      "Epoch 25/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 1.4168 - accuracy: 0.5749 - val_loss: 1.7612 - val_accuracy: 0.5188\n",
      "Epoch 26/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 1.4085 - accuracy: 0.5731 - val_loss: 1.6913 - val_accuracy: 0.5562\n",
      "Epoch 27/200\n",
      "450/450 [==============================] - 442s 981ms/step - loss: 1.4027 - accuracy: 0.5730 - val_loss: 1.8899 - val_accuracy: 0.5312\n",
      "Epoch 28/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 1.4064 - accuracy: 0.5808 - val_loss: 1.4493 - val_accuracy: 0.5375\n",
      "Epoch 29/200\n",
      "450/450 [==============================] - 442s 981ms/step - loss: 1.3695 - accuracy: 0.5869 - val_loss: 1.7067 - val_accuracy: 0.5562\n",
      "Epoch 30/200\n",
      "450/450 [==============================] - 442s 981ms/step - loss: 1.3462 - accuracy: 0.5882 - val_loss: 1.6785 - val_accuracy: 0.5625\n",
      "Epoch 31/200\n",
      "450/450 [==============================] - 442s 981ms/step - loss: 1.3327 - accuracy: 0.6087 - val_loss: 1.4835 - val_accuracy: 0.5375\n",
      "Epoch 32/200\n",
      "450/450 [==============================] - 441s 980ms/step - loss: 1.3021 - accuracy: 0.6069 - val_loss: 1.6307 - val_accuracy: 0.5688\n",
      "Epoch 33/200\n",
      "450/450 [==============================] - 443s 985ms/step - loss: 1.3019 - accuracy: 0.6020 - val_loss: 1.5952 - val_accuracy: 0.5500\n",
      "Epoch 34/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 1.3199 - accuracy: 0.6040 - val_loss: 1.8691 - val_accuracy: 0.4938\n",
      "Epoch 35/200\n",
      "450/450 [==============================] - 443s 984ms/step - loss: 1.2809 - accuracy: 0.6187 - val_loss: 1.4842 - val_accuracy: 0.5750\n",
      "Epoch 36/200\n",
      "450/450 [==============================] - 444s 985ms/step - loss: 1.2732 - accuracy: 0.6084 - val_loss: 1.3189 - val_accuracy: 0.5813\n",
      "Epoch 37/200\n",
      "450/450 [==============================] - 442s 983ms/step - loss: 1.3066 - accuracy: 0.6042 - val_loss: 1.6952 - val_accuracy: 0.5938\n",
      "Epoch 38/200\n",
      "450/450 [==============================] - 442s 983ms/step - loss: 1.2204 - accuracy: 0.6262 - val_loss: 1.5685 - val_accuracy: 0.5375\n",
      "Epoch 39/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 1.2159 - accuracy: 0.6391 - val_loss: 2.1266 - val_accuracy: 0.4625\n",
      "Epoch 40/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 1.1925 - accuracy: 0.6416 - val_loss: 1.8459 - val_accuracy: 0.4938\n",
      "Epoch 41/200\n",
      "450/450 [==============================] - 439s 975ms/step - loss: 1.2578 - accuracy: 0.6189 - val_loss: 1.6531 - val_accuracy: 0.5625\n",
      "Epoch 42/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 1.2284 - accuracy: 0.6218 - val_loss: 1.7149 - val_accuracy: 0.5625\n",
      "Epoch 43/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 1.1561 - accuracy: 0.6376 - val_loss: 1.3801 - val_accuracy: 0.6062\n",
      "Epoch 44/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 1.1926 - accuracy: 0.6369 - val_loss: 1.5008 - val_accuracy: 0.6250\n",
      "Epoch 45/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 1.1962 - accuracy: 0.6356 - val_loss: 1.7175 - val_accuracy: 0.5125\n",
      "Epoch 46/200\n",
      "450/450 [==============================] - 450s 999ms/step - loss: 1.1418 - accuracy: 0.6512 - val_loss: 1.8064 - val_accuracy: 0.4875\n",
      "Epoch 47/200\n",
      "450/450 [==============================] - 445s 988ms/step - loss: 1.2331 - accuracy: 0.6322 - val_loss: 1.6999 - val_accuracy: 0.5562\n",
      "Epoch 48/200\n",
      "450/450 [==============================] - 443s 984ms/step - loss: 1.1844 - accuracy: 0.6371 - val_loss: 1.6218 - val_accuracy: 0.5750\n",
      "Epoch 49/200\n",
      "450/450 [==============================] - 441s 980ms/step - loss: 1.1040 - accuracy: 0.6598 - val_loss: 1.5878 - val_accuracy: 0.5875\n",
      "Epoch 50/200\n",
      "450/450 [==============================] - 441s 981ms/step - loss: 1.2055 - accuracy: 0.6329 - val_loss: 1.6383 - val_accuracy: 0.5562\n",
      "Epoch 51/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 1.0758 - accuracy: 0.6691 - val_loss: 1.9525 - val_accuracy: 0.5437\n",
      "Epoch 52/200\n",
      "450/450 [==============================] - 441s 980ms/step - loss: 1.1245 - accuracy: 0.6578 - val_loss: 1.7306 - val_accuracy: 0.5500\n",
      "Epoch 53/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 1.1119 - accuracy: 0.6600 - val_loss: 1.4806 - val_accuracy: 0.5688\n",
      "Epoch 54/200\n",
      "450/450 [==============================] - 441s 980ms/step - loss: 1.1263 - accuracy: 0.6533 - val_loss: 1.5374 - val_accuracy: 0.5875\n",
      "Epoch 55/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 1.1167 - accuracy: 0.6592 - val_loss: 1.7258 - val_accuracy: 0.5938\n",
      "Epoch 56/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 1.1193 - accuracy: 0.6602 - val_loss: 1.7258 - val_accuracy: 0.4750\n",
      "Epoch 57/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 1.0639 - accuracy: 0.6802 - val_loss: 1.8347 - val_accuracy: 0.5312\n",
      "Epoch 58/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 1.0880 - accuracy: 0.6609 - val_loss: 1.5999 - val_accuracy: 0.5437\n",
      "Epoch 59/200\n",
      "450/450 [==============================] - 446s 991ms/step - loss: 1.0641 - accuracy: 0.6684 - val_loss: 1.9036 - val_accuracy: 0.5875\n",
      "Epoch 60/200\n",
      "450/450 [==============================] - 447s 993ms/step - loss: 1.0832 - accuracy: 0.6673 - val_loss: 1.8469 - val_accuracy: 0.5562\n",
      "Epoch 61/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 1.0805 - accuracy: 0.6691 - val_loss: 1.8139 - val_accuracy: 0.5312\n",
      "Epoch 62/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 1.0718 - accuracy: 0.6672 - val_loss: 1.8753 - val_accuracy: 0.5250\n",
      "Epoch 63/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 1.0302 - accuracy: 0.6773 - val_loss: 1.6175 - val_accuracy: 0.5875\n",
      "Epoch 64/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 1.0705 - accuracy: 0.6719 - val_loss: 1.7144 - val_accuracy: 0.5625\n",
      "Epoch 65/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 1.0408 - accuracy: 0.6800 - val_loss: 1.5280 - val_accuracy: 0.6125\n",
      "Epoch 66/200\n",
      "450/450 [==============================] - 444s 987ms/step - loss: 1.0393 - accuracy: 0.6812 - val_loss: 1.8137 - val_accuracy: 0.5437\n",
      "Epoch 67/200\n",
      "450/450 [==============================] - 446s 990ms/step - loss: 1.0379 - accuracy: 0.6740 - val_loss: 1.8723 - val_accuracy: 0.5250\n",
      "Epoch 68/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 1.0789 - accuracy: 0.6692 - val_loss: 1.9918 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 1.0057 - accuracy: 0.6853 - val_loss: 1.6071 - val_accuracy: 0.5875\n",
      "Epoch 70/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.9980 - accuracy: 0.6858 - val_loss: 1.4434 - val_accuracy: 0.5562\n",
      "Epoch 71/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.9931 - accuracy: 0.6903 - val_loss: 1.8019 - val_accuracy: 0.5250\n",
      "Epoch 72/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 1.0229 - accuracy: 0.6871 - val_loss: 1.9035 - val_accuracy: 0.5625\n",
      "Epoch 73/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 1.0715 - accuracy: 0.6671 - val_loss: 2.0968 - val_accuracy: 0.5063\n",
      "Epoch 74/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 1.0121 - accuracy: 0.6848 - val_loss: 1.8226 - val_accuracy: 0.5312\n",
      "Epoch 75/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 1.0093 - accuracy: 0.6759 - val_loss: 2.3606 - val_accuracy: 0.4062\n",
      "Epoch 76/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 0.9445 - accuracy: 0.7044 - val_loss: 1.7714 - val_accuracy: 0.5312\n",
      "Epoch 77/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 0.9525 - accuracy: 0.7046 - val_loss: 2.0103 - val_accuracy: 0.5188\n",
      "Epoch 78/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 1.0001 - accuracy: 0.6929 - val_loss: 1.7192 - val_accuracy: 0.6187\n",
      "Epoch 79/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 1.0065 - accuracy: 0.6827 - val_loss: 1.8685 - val_accuracy: 0.5938\n",
      "Epoch 80/200\n",
      "450/450 [==============================] - 439s 975ms/step - loss: 0.9656 - accuracy: 0.6979 - val_loss: 1.4279 - val_accuracy: 0.5750\n",
      "Epoch 81/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 0.9863 - accuracy: 0.6929 - val_loss: 2.0428 - val_accuracy: 0.5625\n",
      "Epoch 82/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 0.9740 - accuracy: 0.6946 - val_loss: 2.1676 - val_accuracy: 0.5437\n",
      "Epoch 83/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.9736 - accuracy: 0.6886 - val_loss: 1.8462 - val_accuracy: 0.5437\n",
      "Epoch 84/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 0.9579 - accuracy: 0.7082 - val_loss: 1.9613 - val_accuracy: 0.5437\n",
      "Epoch 85/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.9732 - accuracy: 0.7001 - val_loss: 2.2883 - val_accuracy: 0.4812\n",
      "Epoch 86/200\n",
      "450/450 [==============================] - 439s 975ms/step - loss: 0.9761 - accuracy: 0.6932 - val_loss: 1.9391 - val_accuracy: 0.5875\n",
      "Epoch 87/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 0.9640 - accuracy: 0.7022 - val_loss: 1.5999 - val_accuracy: 0.6125\n",
      "Epoch 88/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 0.9399 - accuracy: 0.7087 - val_loss: 2.1144 - val_accuracy: 0.4938\n",
      "Epoch 89/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 0.9249 - accuracy: 0.7087 - val_loss: 1.9723 - val_accuracy: 0.5500\n",
      "Epoch 90/200\n",
      "450/450 [==============================] - 439s 975ms/step - loss: 0.9337 - accuracy: 0.7178 - val_loss: 1.5982 - val_accuracy: 0.5688\n",
      "Epoch 91/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.9429 - accuracy: 0.7069 - val_loss: 2.0088 - val_accuracy: 0.5250\n",
      "Epoch 92/200\n",
      "450/450 [==============================] - 440s 978ms/step - loss: 0.9469 - accuracy: 0.6991 - val_loss: 2.2691 - val_accuracy: 0.5063\n",
      "Epoch 93/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 0.9538 - accuracy: 0.6997 - val_loss: 1.7305 - val_accuracy: 0.5500\n",
      "Epoch 94/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.9154 - accuracy: 0.7084 - val_loss: 1.7469 - val_accuracy: 0.5625\n",
      "Epoch 95/200\n",
      "450/450 [==============================] - 437s 971ms/step - loss: 0.9229 - accuracy: 0.7064 - val_loss: 1.9126 - val_accuracy: 0.5250\n",
      "Epoch 96/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.9156 - accuracy: 0.7171 - val_loss: 1.9309 - val_accuracy: 0.5813\n",
      "Epoch 97/200\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.9107 - accuracy: 0.7173 - val_loss: 1.7972 - val_accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.9163 - accuracy: 0.7120 - val_loss: 2.0139 - val_accuracy: 0.5500\n",
      "Epoch 99/200\n",
      "450/450 [==============================] - 436s 968ms/step - loss: 0.8535 - accuracy: 0.7275 - val_loss: 2.2656 - val_accuracy: 0.5125\n",
      "Epoch 100/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.8714 - accuracy: 0.7264 - val_loss: 2.0573 - val_accuracy: 0.5375\n",
      "Epoch 101/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.9073 - accuracy: 0.7197 - val_loss: 1.5998 - val_accuracy: 0.5500\n",
      "Epoch 102/200\n",
      "450/450 [==============================] - 436s 969ms/step - loss: 0.9121 - accuracy: 0.7095 - val_loss: 2.2167 - val_accuracy: 0.5813\n",
      "Epoch 103/200\n",
      "450/450 [==============================] - 439s 974ms/step - loss: 0.8696 - accuracy: 0.7173 - val_loss: 1.8655 - val_accuracy: 0.5938\n",
      "Epoch 104/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.9181 - accuracy: 0.7131 - val_loss: 2.1975 - val_accuracy: 0.5625\n",
      "Epoch 105/200\n",
      "450/450 [==============================] - 438s 972ms/step - loss: 0.9115 - accuracy: 0.7150 - val_loss: 1.9594 - val_accuracy: 0.5750\n",
      "Epoch 106/200\n",
      "450/450 [==============================] - 437s 971ms/step - loss: 0.9150 - accuracy: 0.7064 - val_loss: 2.1357 - val_accuracy: 0.5312\n",
      "Epoch 107/200\n",
      "450/450 [==============================] - 437s 970ms/step - loss: 0.8889 - accuracy: 0.7242 - val_loss: 1.8028 - val_accuracy: 0.5188\n",
      "Epoch 108/200\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.9078 - accuracy: 0.7220 - val_loss: 1.7124 - val_accuracy: 0.5938\n",
      "Epoch 109/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.8633 - accuracy: 0.7222 - val_loss: 2.0086 - val_accuracy: 0.5312\n",
      "Epoch 110/200\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.8704 - accuracy: 0.7224 - val_loss: 1.9382 - val_accuracy: 0.5375\n",
      "Epoch 111/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.8876 - accuracy: 0.7180 - val_loss: 2.2552 - val_accuracy: 0.5312\n",
      "Epoch 112/200\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.9183 - accuracy: 0.7027 - val_loss: 1.9243 - val_accuracy: 0.5813\n",
      "Epoch 113/200\n",
      "450/450 [==============================] - 438s 972ms/step - loss: 0.8474 - accuracy: 0.7409 - val_loss: 1.9919 - val_accuracy: 0.5625\n",
      "Epoch 114/200\n",
      "450/450 [==============================] - 437s 971ms/step - loss: 0.8554 - accuracy: 0.7373 - val_loss: 1.7321 - val_accuracy: 0.5938\n",
      "Epoch 115/200\n",
      "450/450 [==============================] - 439s 974ms/step - loss: 0.8757 - accuracy: 0.7198 - val_loss: 2.3421 - val_accuracy: 0.5813\n",
      "Epoch 116/200\n",
      "450/450 [==============================] - 437s 971ms/step - loss: 0.8611 - accuracy: 0.7324 - val_loss: 1.8934 - val_accuracy: 0.6062\n",
      "Epoch 117/200\n",
      "450/450 [==============================] - 437s 970ms/step - loss: 0.8399 - accuracy: 0.7331 - val_loss: 1.8726 - val_accuracy: 0.5875\n",
      "Epoch 118/200\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.8810 - accuracy: 0.7287 - val_loss: 2.0049 - val_accuracy: 0.5562\n",
      "Epoch 119/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.8692 - accuracy: 0.7317 - val_loss: 1.4585 - val_accuracy: 0.6438\n",
      "Epoch 120/200\n",
      "450/450 [==============================] - 439s 975ms/step - loss: 0.8260 - accuracy: 0.7320 - val_loss: 2.0452 - val_accuracy: 0.5500\n",
      "Epoch 121/200\n",
      "450/450 [==============================] - 436s 968ms/step - loss: 0.8732 - accuracy: 0.7237 - val_loss: 2.3288 - val_accuracy: 0.5813\n",
      "Epoch 122/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.8592 - accuracy: 0.7320 - val_loss: 1.9264 - val_accuracy: 0.5625\n",
      "Epoch 123/200\n",
      "450/450 [==============================] - 436s 970ms/step - loss: 0.8476 - accuracy: 0.7346 - val_loss: 1.9989 - val_accuracy: 0.5312\n",
      "Epoch 124/200\n",
      "450/450 [==============================] - 435s 968ms/step - loss: 0.9137 - accuracy: 0.7248 - val_loss: 2.0361 - val_accuracy: 0.5813\n",
      "Epoch 125/200\n",
      "450/450 [==============================] - 436s 968ms/step - loss: 0.8092 - accuracy: 0.7438 - val_loss: 2.1395 - val_accuracy: 0.5750\n",
      "Epoch 126/200\n",
      "450/450 [==============================] - 436s 968ms/step - loss: 0.8508 - accuracy: 0.7329 - val_loss: 1.9098 - val_accuracy: 0.5437\n",
      "Epoch 127/200\n",
      "450/450 [==============================] - 436s 968ms/step - loss: 0.8431 - accuracy: 0.7396 - val_loss: 1.6813 - val_accuracy: 0.6250\n",
      "Epoch 128/200\n",
      "450/450 [==============================] - 436s 969ms/step - loss: 0.8297 - accuracy: 0.7420 - val_loss: 2.2508 - val_accuracy: 0.4875\n",
      "Epoch 129/200\n",
      "450/450 [==============================] - 436s 969ms/step - loss: 0.8524 - accuracy: 0.7298 - val_loss: 2.2537 - val_accuracy: 0.5625\n",
      "Epoch 130/200\n",
      "450/450 [==============================] - 435s 967ms/step - loss: 0.8306 - accuracy: 0.7349 - val_loss: 2.1398 - val_accuracy: 0.5437\n",
      "Epoch 131/200\n",
      "450/450 [==============================] - 437s 970ms/step - loss: 0.8320 - accuracy: 0.7349 - val_loss: 2.0287 - val_accuracy: 0.6000\n",
      "Epoch 132/200\n",
      "450/450 [==============================] - 436s 970ms/step - loss: 0.8167 - accuracy: 0.7400 - val_loss: 1.9116 - val_accuracy: 0.6125\n",
      "Epoch 133/200\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.8310 - accuracy: 0.7304 - val_loss: 2.0843 - val_accuracy: 0.6125\n",
      "Epoch 134/200\n",
      "450/450 [==============================] - 436s 969ms/step - loss: 0.8422 - accuracy: 0.7358 - val_loss: 2.4390 - val_accuracy: 0.5125\n",
      "Epoch 135/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.8120 - accuracy: 0.7542 - val_loss: 2.2188 - val_accuracy: 0.5250\n",
      "Epoch 136/200\n",
      "450/450 [==============================] - 437s 970ms/step - loss: 0.8120 - accuracy: 0.7507 - val_loss: 1.9734 - val_accuracy: 0.5688\n",
      "Epoch 137/200\n",
      "450/450 [==============================] - 436s 969ms/step - loss: 0.8084 - accuracy: 0.7471 - val_loss: 1.8624 - val_accuracy: 0.6250\n",
      "Epoch 138/200\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.8181 - accuracy: 0.7449 - val_loss: 1.8841 - val_accuracy: 0.5813\n",
      "Epoch 139/200\n",
      "450/450 [==============================] - 437s 970ms/step - loss: 0.8412 - accuracy: 0.7369 - val_loss: 2.1582 - val_accuracy: 0.5312\n",
      "Epoch 140/200\n",
      "450/450 [==============================] - 438s 972ms/step - loss: 0.8295 - accuracy: 0.7453 - val_loss: 1.9972 - val_accuracy: 0.5562\n",
      "Epoch 141/200\n",
      "450/450 [==============================] - 437s 971ms/step - loss: 0.8022 - accuracy: 0.7487 - val_loss: 1.7588 - val_accuracy: 0.5688\n",
      "Epoch 142/200\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.7810 - accuracy: 0.7540 - val_loss: 2.2691 - val_accuracy: 0.6000\n",
      "Epoch 143/200\n",
      "450/450 [==============================] - 437s 971ms/step - loss: 0.8121 - accuracy: 0.7469 - val_loss: 1.9227 - val_accuracy: 0.5813\n",
      "Epoch 144/200\n",
      "450/450 [==============================] - 438s 973ms/step - loss: 0.7797 - accuracy: 0.7493 - val_loss: 2.1357 - val_accuracy: 0.5188\n",
      "Epoch 145/200\n",
      "450/450 [==============================] - 437s 972ms/step - loss: 0.8582 - accuracy: 0.7344 - val_loss: 1.7512 - val_accuracy: 0.6438\n",
      "Epoch 146/200\n",
      "450/450 [==============================] - 438s 972ms/step - loss: 0.7995 - accuracy: 0.7562 - val_loss: 1.9515 - val_accuracy: 0.5688\n",
      "Epoch 147/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.7953 - accuracy: 0.7518 - val_loss: 2.0580 - val_accuracy: 0.5562\n",
      "Epoch 148/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 0.8006 - accuracy: 0.7444 - val_loss: 2.1643 - val_accuracy: 0.5375\n",
      "Epoch 149/200\n",
      "450/450 [==============================] - 440s 977ms/step - loss: 0.8021 - accuracy: 0.7429 - val_loss: 2.6053 - val_accuracy: 0.5437\n",
      "Epoch 150/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.8254 - accuracy: 0.7440 - val_loss: 1.8205 - val_accuracy: 0.6000\n",
      "Epoch 151/200\n",
      "450/450 [==============================] - 439s 976ms/step - loss: 0.8014 - accuracy: 0.7460 - val_loss: 1.9444 - val_accuracy: 0.5688\n",
      "Epoch 152/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 0.7900 - accuracy: 0.7644 - val_loss: 2.1073 - val_accuracy: 0.5813\n",
      "Epoch 153/200\n",
      "450/450 [==============================] - 441s 979ms/step - loss: 0.7639 - accuracy: 0.7524 - val_loss: 2.0046 - val_accuracy: 0.5938\n",
      "Epoch 154/200\n",
      "450/450 [==============================] - 441s 980ms/step - loss: 0.7821 - accuracy: 0.7516 - val_loss: 2.2472 - val_accuracy: 0.5312\n",
      "Epoch 155/200\n",
      "450/450 [==============================] - 441s 981ms/step - loss: 0.7668 - accuracy: 0.7502 - val_loss: 2.2663 - val_accuracy: 0.5250\n",
      "Epoch 156/200\n",
      "450/450 [==============================] - 441s 980ms/step - loss: 0.7881 - accuracy: 0.7500 - val_loss: 2.1956 - val_accuracy: 0.5500\n",
      "Epoch 157/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 0.8074 - accuracy: 0.7547 - val_loss: 2.4630 - val_accuracy: 0.5437\n",
      "Epoch 158/200\n",
      "450/450 [==============================] - 443s 984ms/step - loss: 0.7959 - accuracy: 0.7549 - val_loss: 2.0413 - val_accuracy: 0.5437\n",
      "Epoch 159/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 0.7948 - accuracy: 0.7545 - val_loss: 2.7265 - val_accuracy: 0.4812\n",
      "Epoch 160/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 0.7903 - accuracy: 0.7542 - val_loss: 2.5283 - val_accuracy: 0.5125\n",
      "Epoch 161/200\n",
      "450/450 [==============================] - 444s 986ms/step - loss: 0.8058 - accuracy: 0.7442 - val_loss: 2.1723 - val_accuracy: 0.5375\n",
      "Epoch 162/200\n",
      "450/450 [==============================] - 444s 986ms/step - loss: 0.7452 - accuracy: 0.7593 - val_loss: 2.2589 - val_accuracy: 0.5125\n",
      "Epoch 163/200\n",
      "450/450 [==============================] - 442s 982ms/step - loss: 0.7563 - accuracy: 0.7687 - val_loss: 1.5125 - val_accuracy: 0.6375\n",
      "Epoch 164/200\n",
      "450/450 [==============================] - 443s 985ms/step - loss: 0.8114 - accuracy: 0.7500 - val_loss: 2.2069 - val_accuracy: 0.5875\n",
      "Epoch 165/200\n",
      "450/450 [==============================] - 444s 987ms/step - loss: 0.7719 - accuracy: 0.7580 - val_loss: 2.2099 - val_accuracy: 0.5688\n",
      "Epoch 166/200\n",
      "450/450 [==============================] - 442s 983ms/step - loss: 0.7546 - accuracy: 0.7571 - val_loss: 2.0882 - val_accuracy: 0.5875\n",
      "Epoch 167/200\n",
      "450/450 [==============================] - 442s 983ms/step - loss: 0.7763 - accuracy: 0.7596 - val_loss: 2.2692 - val_accuracy: 0.5125\n",
      "Epoch 168/200\n",
      "450/450 [==============================] - 442s 983ms/step - loss: 0.7438 - accuracy: 0.7656 - val_loss: 2.3525 - val_accuracy: 0.5562\n",
      "Epoch 169/200\n",
      "450/450 [==============================] - 444s 986ms/step - loss: 0.7844 - accuracy: 0.7427 - val_loss: 2.3148 - val_accuracy: 0.5625\n",
      "Epoch 170/200\n",
      "450/450 [==============================] - 444s 986ms/step - loss: 0.7564 - accuracy: 0.7624 - val_loss: 1.9498 - val_accuracy: 0.5875\n",
      "Epoch 171/200\n",
      "450/450 [==============================] - 444s 986ms/step - loss: 0.7649 - accuracy: 0.7565 - val_loss: 1.8993 - val_accuracy: 0.5938\n",
      "Epoch 172/200\n",
      "450/450 [==============================] - 445s 988ms/step - loss: 0.7632 - accuracy: 0.7567 - val_loss: 2.5805 - val_accuracy: 0.5375\n",
      "Epoch 173/200\n",
      "450/450 [==============================] - 446s 992ms/step - loss: 0.7525 - accuracy: 0.7600 - val_loss: 2.5832 - val_accuracy: 0.5125\n",
      "Epoch 174/200\n",
      "450/450 [==============================] - 445s 989ms/step - loss: 0.7563 - accuracy: 0.7607 - val_loss: 2.2898 - val_accuracy: 0.5875\n",
      "Epoch 175/200\n",
      "450/450 [==============================] - 446s 991ms/step - loss: 0.7712 - accuracy: 0.7569 - val_loss: 2.3997 - val_accuracy: 0.5813\n",
      "Epoch 176/200\n",
      "450/450 [==============================] - 446s 990ms/step - loss: 0.7230 - accuracy: 0.7724 - val_loss: 2.2547 - val_accuracy: 0.5375\n",
      "Epoch 177/200\n",
      "450/450 [==============================] - 445s 989ms/step - loss: 0.7462 - accuracy: 0.7678 - val_loss: 2.7413 - val_accuracy: 0.5375\n",
      "Epoch 178/200\n",
      "450/450 [==============================] - 447s 993ms/step - loss: 0.7319 - accuracy: 0.7636 - val_loss: 2.2247 - val_accuracy: 0.5312\n",
      "Epoch 179/200\n",
      "450/450 [==============================] - 447s 994ms/step - loss: 0.7414 - accuracy: 0.7669 - val_loss: 2.0316 - val_accuracy: 0.5625\n",
      "Epoch 180/200\n",
      "450/450 [==============================] - 449s 998ms/step - loss: 0.7318 - accuracy: 0.7733 - val_loss: 2.1588 - val_accuracy: 0.6000\n",
      "Epoch 181/200\n",
      "450/450 [==============================] - 448s 996ms/step - loss: 0.7297 - accuracy: 0.7698 - val_loss: 1.9641 - val_accuracy: 0.5813\n",
      "Epoch 182/200\n",
      "450/450 [==============================] - 448s 995ms/step - loss: 0.7682 - accuracy: 0.7576 - val_loss: 1.9650 - val_accuracy: 0.6438\n",
      "Epoch 183/200\n",
      "450/450 [==============================] - 448s 996ms/step - loss: 0.7451 - accuracy: 0.7656 - val_loss: 2.0734 - val_accuracy: 0.6313\n",
      "Epoch 184/200\n",
      "450/450 [==============================] - 447s 992ms/step - loss: 0.7395 - accuracy: 0.7707 - val_loss: 2.1681 - val_accuracy: 0.5813\n",
      "Epoch 185/200\n",
      "450/450 [==============================] - 449s 997ms/step - loss: 0.7907 - accuracy: 0.7491 - val_loss: 2.4809 - val_accuracy: 0.5562\n",
      "Epoch 186/200\n",
      "450/450 [==============================] - 448s 996ms/step - loss: 0.7165 - accuracy: 0.7604 - val_loss: 2.2217 - val_accuracy: 0.5375\n",
      "Epoch 187/200\n",
      "450/450 [==============================] - 448s 996ms/step - loss: 0.7319 - accuracy: 0.7676 - val_loss: 2.5507 - val_accuracy: 0.5125\n",
      "Epoch 188/200\n",
      "450/450 [==============================] - 448s 995ms/step - loss: 0.7122 - accuracy: 0.7720 - val_loss: 2.3414 - val_accuracy: 0.5437\n",
      "Epoch 189/200\n",
      "450/450 [==============================] - 448s 995ms/step - loss: 0.7354 - accuracy: 0.7700 - val_loss: 2.2924 - val_accuracy: 0.5250\n",
      "Epoch 190/200\n",
      "450/450 [==============================] - 448s 995ms/step - loss: 0.7276 - accuracy: 0.7649 - val_loss: 2.3497 - val_accuracy: 0.5688\n",
      "Epoch 191/200\n",
      "450/450 [==============================] - 446s 990ms/step - loss: 0.7743 - accuracy: 0.7591 - val_loss: 2.0234 - val_accuracy: 0.5875\n",
      "Epoch 192/200\n",
      "450/450 [==============================] - 444s 986ms/step - loss: 0.7446 - accuracy: 0.7711 - val_loss: 2.1069 - val_accuracy: 0.5437\n",
      "Epoch 193/200\n",
      "450/450 [==============================] - 445s 989ms/step - loss: 0.7154 - accuracy: 0.7771 - val_loss: 2.7973 - val_accuracy: 0.5125\n",
      "Epoch 194/200\n",
      "450/450 [==============================] - 446s 990ms/step - loss: 0.7404 - accuracy: 0.7660 - val_loss: 2.1837 - val_accuracy: 0.5250\n",
      "Epoch 195/200\n",
      "450/450 [==============================] - 448s 995ms/step - loss: 0.7174 - accuracy: 0.7731 - val_loss: 2.4318 - val_accuracy: 0.5312\n",
      "Epoch 196/200\n",
      "450/450 [==============================] - 446s 991ms/step - loss: 0.7102 - accuracy: 0.7705 - val_loss: 2.3180 - val_accuracy: 0.5500\n",
      "Epoch 197/200\n",
      "450/450 [==============================] - 447s 994ms/step - loss: 0.7481 - accuracy: 0.7604 - val_loss: 2.5570 - val_accuracy: 0.5250\n",
      "Epoch 198/200\n",
      "450/450 [==============================] - 446s 992ms/step - loss: 0.7135 - accuracy: 0.7767 - val_loss: 2.3970 - val_accuracy: 0.5625\n",
      "Epoch 199/200\n",
      "450/450 [==============================] - 448s 995ms/step - loss: 0.7464 - accuracy: 0.7702 - val_loss: 2.4535 - val_accuracy: 0.5437\n",
      "Epoch 200/200\n",
      "450/450 [==============================] - 448s 994ms/step - loss: 0.6975 - accuracy: 0.7784 - val_loss: 2.2365 - val_accuracy: 0.6062\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# fit the mdel\n",
    "r=model.fit_generator(training_set,\n",
    "validation_data=test_set,\n",
    "epochs=200,\n",
    "steps_per_epoch=len(training_set)//3,\n",
    "validation_steps=len(test_set)//3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tihan/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#Save Model\n",
    "model.save(\"sports_classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model(\"sports_classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 585ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'boxing'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img(r\"D:\\smartbridge data science\\project\\main\\dataset\\test\\boxing\\2.jpg\",target_size=(224,224))\n",
    "x=image.img_to_array(img)\n",
    "import numpy as np\n",
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "output=np.argmax(model.predict(img_data),axis=1)\n",
    "index=['air hockey', 'ampute football', 'archery', 'arm wrestling', 'axe throwing', 'balance beam', 'barell racing', 'baseball', \n",
    "       'basketball', 'baton twirling', 'bike polo', 'billiards', 'bmx', 'bobsled', 'bowling', 'boxing', 'bull riding', 'bungee jumping', \n",
    "       'canoe slamon', 'cheerleading', 'chuckwagon racing', 'cricket', 'croquet', 'curling', 'disc golf', 'fencing', 'field hockey', 'figure skating men', \n",
    "       'figure skating pairs', 'figure skating women', 'fly fishing', 'football', 'formula 1 racing', 'frisbee', 'gaga', 'giant slalom', \n",
    "       'golf', 'hammer throw', 'hang gliding', 'harness racing', 'high jump', 'hockey', 'horse jumping', 'horse racing', 'horseshoe pitching', \n",
    "       'hurdles', 'hydroplane racing', 'ice climbing', 'ice yachting', 'jai alai', 'javelin', 'jousting', 'judo', 'lacrosse', 'log rolling', \n",
    "       'luge', 'motorcycle racing', 'mushing', 'nascar racing', 'olympic wrestling', 'parallel bar', 'pole climbing', 'pole dancing', 'pole vault', \n",
    "       'polo', 'pommel horse', 'rings', 'rock climbing', 'roller derby', 'rollerblade racing', 'rowing', 'rugby', 'sailboat racing', 'shot put', \n",
    "       'shuffleboard', 'sidecar racing', 'ski jumping', 'sky surfing', 'skydiving', 'snow boarding', 'snowmobile racing', 'speed skating', 'steer wrestling', \n",
    "       'sumo wrestling', 'surfing', 'swimming', 'table tennis', 'tennis', 'track bicycle', 'trapeze', 'tug of war', 'ultimate', 'uneven bars', 'volleyball', \n",
    "       'water cycling', 'water polo', 'weightlifting', 'wheelchair basketball', 'wheelchair racing', 'wingsuit flying']\n",
    "\n",
    "result=str(index[output[0]])\n",
    "result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
